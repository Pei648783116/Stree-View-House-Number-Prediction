{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN Notebook\n",
    "Project : Street View House Numbers\n",
    "By: Peiyao (Celine) Li , and Kevin Liu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all libraries\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pandas as pd\n",
    "import io\n",
    "from PIL import Image\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.io import loadmat\n",
    "from sklearn import preprocessing\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the dataset from desktop\n",
    "tr_set = \"C:/Users/Celin/Desktop/CelineFirstJupyter/Street_num Final Project/Format 2/train_32x32.mat\"\n",
    "te_set = \"C:/Users/Celin/Desktop/CelineFirstJupyter/Street_num Final Project/Format 2/test_32x32.mat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format 2 dataset load-in\n",
    "data = loadmat(tr_set)\n",
    "te_data = loadmat(te_set)\n",
    "\n",
    "X_tr, y_tr = data['X'], data['y']\n",
    "X_te, y_te = te_data['X'], te_data['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Shape Params: <width, height, channels [rgb], # of images>\n",
      "X Shape:  (32, 32, 3, 73257)  y Shape:  (73257, 1)\n"
     ]
    }
   ],
   "source": [
    "# explore training data details\n",
    "print (\"Training Set Shape Params: <width, height, channels [rgb], # of images>\")\n",
    "print(\"X Shape: \", X_tr.shape, \" y Shape: \", y_tr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(225045504, 79970304)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#explore numbers of pixels in total in each set\n",
    "X_tr.size, X_te.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Shape:  (73257, 32, 32, 3)  y Shape:  (73257,)\n"
     ]
    }
   ],
   "source": [
    "# transpose data to (# of images, width, height, rgb)\n",
    "X_tr, y_tr = X_tr.transpose((3,0,1,2)), y_tr[:,0]\n",
    "X_te, y_te = X_te.transpose((3,0,1,2)), y_te[:,0]\n",
    "print(\"X Shape: \", X_tr.shape, \" y Shape: \", y_tr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 5099, 2: 4149, 3: 2882, 4: 2523, 5: 2384, 7: 2019, 6: 1977, 10: 1744, 8: 1660, 9: 1595})\n",
      "Counter({1: 13861, 2: 10585, 3: 8497, 4: 7458, 5: 6882, 6: 5727, 7: 5595, 8: 5045, 10: 4948, 9: 4659})\n"
     ]
    }
   ],
   "source": [
    "#count the number of original data per label n test and training data\n",
    "import collections\n",
    "print(collections.Counter(y_te))\n",
    "print(collections.Counter(y_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take 2000 training data and 400 test data\n",
    "X_tr_new=[]\n",
    "y_tr_new=[]\n",
    "X_te_new=[]\n",
    "y_te_new=[]\n",
    "# y_train_new=list(y_train)\n",
    "# X_train_new=list(X_train)\n",
    "\n",
    "for i in range(1,11):\n",
    "    for a,b in zip(X_tr,y_tr):\n",
    "        if b == i and y_tr_new.count(i)<200:\n",
    "            X_tr_new.append(a)\n",
    "            y_tr_new.append(b)\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "for i in range(1,11):\n",
    "    for a,b in zip(X_te,y_te):\n",
    "        if b == i and y_te_new.count(i)<80:\n",
    "            X_te_new.append(a)\n",
    "            y_te_new.append(b)\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "80\n",
      "200\n",
      "80\n",
      "200\n",
      "80\n",
      "200\n",
      "80\n",
      "200\n",
      "80\n",
      "200\n",
      "80\n",
      "200\n",
      "80\n",
      "200\n",
      "80\n",
      "200\n",
      "80\n",
      "200\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "#double check the count of each label in the new data\n",
    "for i in range(1,11):\n",
    "    print(y_tr_new.count(i))\n",
    "    print(y_te_new.count(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Shape:  (2000, 32, 32, 3)  y Shape:  (2000,)\n"
     ]
    }
   ],
   "source": [
    "X_tr=np.array(X_tr_new)\n",
    "y_tr= np.array(y_tr_new)\n",
    "X_te=np.array(X_te_new)\n",
    "y_te= np.array(y_te_new)\n",
    "print(\"X Shape: \", X_tr.shape, \" y Shape: \", y_tr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore all the labels , note that 0 was originally labled as 10\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "# print(y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change all label \"10\" to 0 as shown in images\n",
    "for i in range(len(y_tr)):\n",
    "    if (y_tr[i]==10):\n",
    "        y_tr[i]=0\n",
    "for i in range(len(y_te)):\n",
    "    if (y_te[i]==10):\n",
    "        y_te[i]=0  \n",
    "# print(y_tr)#check to see the new labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set (2000, 32, 32, 1)\n",
      "Testing Set (800, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "# convert RGB to grayscale\n",
    "def rgb2gray(img_data):\n",
    "    return np.expand_dims(np.dot(img_data, [0.3, 0.6, 0.1]), axis=3)\n",
    "\n",
    "X_tr_gr = rgb2gray(X_tr).astype(np.float32) # converts gray training set to float values\n",
    "print(\"Training Set\", X_tr_gr.shape)\n",
    "X_tr = X_tr_gr # replace original training set\n",
    "\n",
    "X_te_gr = rgb2gray(X_te).astype(np.float32) # converts gray testing set to float values\n",
    "print(\"Testing Set\", X_te_gr.shape)\n",
    "X_te = X_te_gr # replace original testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show an example image using gray scale\n",
    "digit_img = X_tr[0].reshape((32,32))\n",
    "plt.imshow(digit_img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 2048000 into shape (73257,1024)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-35b773d78562>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_tr_resized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_tr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m73257\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mX_te_resized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_te\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m26032\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 2048000 into shape (73257,1024)"
     ]
    }
   ],
   "source": [
    "X_tr_resized = X_tr.reshape(73257, 32*32*1)\n",
    "X_te_resized = X_te.reshape(26032, 32*32*1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_tr = sc_X.fit_transform(X_tr_resized)\n",
    "X_te = sc_X.transform(X_te_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train and test set\n",
    "train_images = X_tr\n",
    "test_images = X_te\n",
    "train_labels = y_tr\n",
    "test_labels = y_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print max values to scale the values \n",
    "print(np.max(train_images))\n",
    "print(np.max(test_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the values between 0 to 1\n",
    "# train_images, test_images = train_images / 255.0, test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#CNN model define the 3 layers \n",
    "# the first two convolutional layers are followed by a MaxPooling where the size of the output is reduced\n",
    "# 3 by 3 is standard filter size in CNN, and 32/64/128 are the standard output channel depths, by convention the latter layers have more depth\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(64, (3, 3), input_shape=(1)))\n",
    "model.add(layers.LeakyReLU(alpha=0.1))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3)))\n",
    "model.add(layers.LeakyReLU(alpha=0.1))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3)))\n",
    "model.add(layers.LeakyReLU(alpha=0.1))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define dense layer array\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dropout(0.4))#it is found that dropout=0.4 peforms best\n",
    "#model.add(layers.LeakyReLU(alpha=0.1)) , it is found the this dense layer performs better with relu rather than leaky relu\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# compile model and train the dataset\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing accuracy output\n",
    "print(test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the softmax distribution for each category for the first 10 images and print their labels\n",
    "output = model.predict(test_images[:10])\n",
    "print(output)\n",
    "print(np.argmax(output, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view 10 test images to make sure they actually match their labels printed above, and they do! yay!\n",
    "X_orig_tr = data['X']\n",
    "X_orig_te = te_data['X']\n",
    "\n",
    "for i in range(0,10):\n",
    "    show_img = X_te[i].reshape((32,32))\n",
    "    print(show_img.shape,y_te[i])\n",
    "    plt.imshow(show_img)\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
