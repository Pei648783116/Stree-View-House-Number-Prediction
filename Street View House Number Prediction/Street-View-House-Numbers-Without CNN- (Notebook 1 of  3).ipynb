{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVHN Classification Without Neural Nets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE THAT THIS NOTEBOOK WILL TAKE AROUND 8 HOURS TO RUN IN TOTAL DUE TO HYPERPARAMATER SEARCHING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook focuses on classifying the Street View House Numbers dataset using the following techniques to classify street view house numbers: support vector (SVC), random forest, logistic regression, k-nearest neighbors (KNN) ane ensemble of the above. The dataset can be found at http://ufldl.stanford.edu/housenumbers/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following preprocessing techniques were used: Reshaping the dataset, converting RGB to grayscale, scaling the data, and undersampling the training data to select 2000 data from the whole dataset and have an even distribution among classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Celin\\Anaconda3\\lib\\site-packages\\dask\\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import io\n",
    "from PIL import Image\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVR\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.io import loadmat\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler()\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from skimage import color\n",
    "from skimage.feature import hog\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load in the datasets using loadmat, and preprocess the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to original very large dataset\n",
    "tr_set = \"C:/Users/Celin/Desktop/CelineFirstJupyter/Street_num Final Project/Format 2/train_32x32.mat\"\n",
    "te_set = \"C:/Users/Celin/Desktop/CelineFirstJupyter/Street_num Final Project/Format 2/test_32x32.mat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load-in whole data set\n",
    "data = loadmat(tr_set)\n",
    "te_data = loadmat(te_set)\n",
    "\n",
    "X_tr, y_tr = data['X'], data['y']\n",
    "X_te, y_te = te_data['X'], te_data['y']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Shape Params: <width, height, channels [rgb], # of images>\n",
      "X Shape:  (32, 32, 3, 73257)  y Shape:  (73257, 1)\n"
     ]
    }
   ],
   "source": [
    "# training data details\n",
    "print (\"Training Set Shape Params: <width, height, channels [rgb], # of images>\")\n",
    "print(\"X Shape: \", X_tr.shape, \" y Shape: \", y_tr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transpose data to (# of images, width, height, rgb)\n",
    "X_tr, y_tr = X_tr.transpose((3,0,1,2)), y_tr[:,0]\n",
    "X_te, y_te = X_te.transpose((3,0,1,2)), y_te[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take 2000 training data and 400 test data from the original dataset as our dataset\n",
    "X_tr_new=[]\n",
    "y_tr_new=[]\n",
    "X_te_new=[]\n",
    "y_te_new=[]\n",
    "# y_train_new=list(y_train)\n",
    "# X_train_new=list(X_train)\n",
    "\n",
    "for i in range(1,11):\n",
    "    for a,b in zip(X_tr,y_tr):\n",
    "        if b == i and y_tr_new.count(i)<200:\n",
    "            X_tr_new.append(a)\n",
    "            y_tr_new.append(b)\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "for i in range(1,11):\n",
    "    for a,b in zip(X_te,y_te):\n",
    "        if b == i and y_te_new.count(i)<80:\n",
    "            X_te_new.append(a)\n",
    "            y_te_new.append(b)\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Shape:  (2000, 32, 32, 3)  y Shape:  (2000,)\n"
     ]
    }
   ],
   "source": [
    "X_tr=np.array(X_tr_new)\n",
    "y_tr= np.array(y_tr_new)\n",
    "X_te=np.array(X_te_new)\n",
    "y_te= np.array(y_te_new)\n",
    "print(\"X Shape: \", X_tr.shape, \" y Shape: \", y_tr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set (2000, 32, 32, 1)\n",
      "Training Set (800, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "# convert RGB to grayscale for feature engineering\n",
    "def rgb2gray(img_data):\n",
    "    return np.expand_dims(np.dot(img_data, [0.3, 0.6, 0.1]), axis=3)\n",
    "\n",
    "X_tr_gr = rgb2gray(X_tr).astype(np.float32) # converts gray training set to float values\n",
    "X_te_gr = rgb2gray(X_te).astype(np.float32)\n",
    "\n",
    "X_tr = X_tr_gr # replace original training set\n",
    "X_te = X_te_gr\n",
    "print(\"Training Set\", X_tr.shape)\n",
    "print(\"Testing Set\", X_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#see can example greyscale image, clarity is still pretty good\n",
    "digit_img = X_tr[0].reshape((32,32))\n",
    "plt.imshow(digit_img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#more data pre-processing, rreshae the data to the correct form we can use to fit and train\n",
    "X_tr_resized = X_tr.reshape(2000, 32*32*1)\n",
    "X_te_resized = X_te.reshape(800, 32*32*1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale our data (normalization) - feature engineering\n",
    "sc_X = StandardScaler()\n",
    "X_tr_scaled = sc_X.fit_transform(X_tr_resized)\n",
    "X_te_scaled = sc_X.transform(X_te_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 1024)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 200,\n",
       "         2: 200,\n",
       "         3: 200,\n",
       "         4: 200,\n",
       "         5: 200,\n",
       "         6: 200,\n",
       "         7: 200,\n",
       "         8: 200,\n",
       "         9: 200,\n",
       "         10: 200})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm each trainning class has exactly 200 dataset\n",
    "from collections import Counter\n",
    "Counter(y_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit and Evaluate Various Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The section below shows various models here, and compare test accuracies. For example, I used random search for random forest and KNN, and grid search for SVC to find the optimal parameters. Because search time is quite significant, some models with a a lot of hyperpramaters possibilities used random search instead of grid search. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest With and Without PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_noPCA = RandomForestClassifier(n_estimators=10, oob_score=True, random_state=42, min_samples_leaf=1, max_features=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Celin\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\Celin\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=True, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_noPCA.fit(X_tr_scaled, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_noPCA_prediction = rf_noPCA.predict(X_te_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2675"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy of no PCA and default random forest \n",
    "accuracy_score(y_te,rf_noPCA_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest without PCA and without hyperapramater tuning-> only 27% test accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning for Random Forest w/o PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we search for optimal hyperparameters for the random forest algorithm using 3-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random search for optimal parameters of random forest\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [50,100,500]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [10,50,200]\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [3,5]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1,2,4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': [50, 100, 500],\n",
       " 'max_features': ['auto'],\n",
       " 'max_depth': [10, 50, 200],\n",
       " 'min_samples_split': [3, 5],\n",
       " 'min_samples_leaf': [1, 2, 4],\n",
       " 'bootstrap': [True, False]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  9.2min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 18.4min finished\n",
      "C:\\Users\\Celin\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "          estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False),\n",
       "          fit_params=None, iid='warn', n_iter=100, n_jobs=-1,\n",
       "          param_distributions={'n_estimators': [50, 100, 500], 'max_features': ['auto'], 'max_depth': [10, 50, 200], 'min_samples_split': [3, 5], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=42)\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_tr_scaled, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 500,\n",
       " 'min_samples_split': 3,\n",
       " 'min_samples_leaf': 2,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': 200,\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the random forest using the above best paramaters after random search\n",
    "new_rfc = rf_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=False, class_weight=None,\n",
       "            criterion='entropy', max_depth=200, max_features='auto',\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=2,\n",
       "            min_samples_split=3, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=500, n_jobs=None, oob_score=False,\n",
       "            random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_rfc.fit(X_tr_scaled, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4875"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_predictRf = new_rfc.predict(X_te_scaled)\n",
    "accuracy_score(y_te, new_predictRf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new hyperparameters used after searching achieved a higher test accuracy of 49% in comparison with the previous default hyperparameters with 27%.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning for Random Forest with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(0.95)\n",
    "X_tr_new = pca.fit_transform(X_tr_scaled)\n",
    "X_te_new = pca.transform(X_te_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   22.9s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  4.2min finished\n",
      "C:\\Users\\Celin\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "          estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False),\n",
       "          fit_params=None, iid='warn', n_iter=100, n_jobs=-1,\n",
       "          param_distributions={'n_estimators': [50, 100, 500], 'max_features': ['auto'], 'max_depth': [10, 50, 200], 'min_samples_split': [3, 5], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=2)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=42)\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_tr_new, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 500,\n",
       " 'min_samples_split': 3,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': 50,\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the random forest using the above best paramaters after random search\n",
    "new_rfc = rf_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50125"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_predictRf = new_rfc.predict(X_te_new)\n",
    "accuracy_score(y_te, new_predictRf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The randomforest's accuracy after PCA preserving 95% variance and hyperparamater tunning increased slightly to 50% from the 49% without PCA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[47,  4,  3,  5,  3,  0,  5,  3,  5,  5],\n",
       "       [ 2, 41,  7,  2,  7,  0, 10,  4,  5,  2],\n",
       "       [ 9,  6, 32,  3,  7,  3,  7,  1,  8,  4],\n",
       "       [ 3,  3,  3, 51,  2,  2,  6,  3,  4,  3],\n",
       "       [ 2,  6,  7,  3, 34,  7,  3,  4, 10,  4],\n",
       "       [ 7,  4,  1, 11,  5, 29,  4,  8,  4,  7],\n",
       "       [ 2,  9,  4,  2,  2,  0, 51,  2,  6,  2],\n",
       "       [ 2,  7,  3,  0,  3,  4,  6, 31, 16,  8],\n",
       "       [ 2,  4,  3,  7,  1,  1,  6,  3, 46,  7],\n",
       "       [ 3,  2,  2,  3,  6,  7,  3,  1, 14, 39]], dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_te,new_predictRf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the confusion matrix:\n",
    "it seems a lot of 6 are wrongly classified as 4 and 8.\n",
    "A lot of 0s are wrongly classified as 9.\n",
    "A lot of 7s are wrong classified as 2\n",
    "A lot of 5 are wrongly classified as 9\n",
    "\n",
    "These are all make sense as 6,8,9 have a lot of circles and curvatures. \n",
    "7 and 2 could look very similar in hand writting as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN classifier with and without PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use a K-nearest neighbors model to predict on the test data, after applying principal component analysis on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# train KNN classifier\n",
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.528"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#KNN without PCA training accuracy score\n",
    "knn.fit(X_tr_scaled, y_tr)\n",
    "knn_pred_tr = knn.predict(X_tr_scaled)\n",
    "accuracy_score(y_tr, knn_pred_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27375"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#KNN default model without PCA testing accuracy score\n",
    "knn_pred_te = knn.predict(X_te_scaled)\n",
    "accuracy_score(y_te, knn_pred_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN no PCA Hyper-paramater tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': [2, 5, 7, 9, 10, 12, 15, 17, 18, 19, 20]}\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   32.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "          estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "          fit_params=None, iid='warn', n_iter=5, n_jobs=-1,\n",
       "          param_distributions={'n_neighbors': [2, 5, 7, 9, 10, 12, 15, 17, 18, 19, 20]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=2)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clearly overfitted when training accuracy is much higher than testing\n",
    "#need to use random search to find the best KNN model paramater\n",
    "neighbours=[2,5,7,9,10,12,15,17,18,19,20]\n",
    "random_grid = {'n_neighbors': neighbours}\n",
    "print(random_grid)\n",
    "knn_random = RandomizedSearchCV(estimator = knn, param_distributions = random_grid, n_iter = 5, cv = 3, verbose=2, n_jobs = -1)\n",
    "knn_random.fit(X_tr_scaled, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 18}\n"
     ]
    }
   ],
   "source": [
    "print(knn_random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.411"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_noPCA = knn_random.best_estimator_\n",
    "knn_pred_tr = knn_noPCA.predict(X_tr_scaled)\n",
    "accuracy_score(y_tr, knn_pred_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28125"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_pred_te = knn_noPCA.predict(X_te_scaled)\n",
    "accuracy_score(y_te, knn_pred_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test accuracy for KNN without PCA increased from 27% to 28% after hyper-paramater searching."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  KNN with PCA Model  Hyper-paramater Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    1.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 7}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5055"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eighbours=[2,5,7,9,10,12,15,17,18,19,20]\n",
    "random_grid = {'n_neighbors': neighbours}\n",
    "knn_random = RandomizedSearchCV(estimator = knn, param_distributions = random_grid, n_iter = 5, cv = 3, verbose=2, n_jobs = -1)\n",
    "knn_random.fit(X_tr_new, y_tr)\n",
    "print(knn_random.best_params_)\n",
    "knn_PCA = knn_random.best_estimator_\n",
    "knn_pred_tr = knn_PCA.predict(X_tr_new)\n",
    "accuracy_score(y_tr, knn_pred_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test set prediction\n",
    "knn_pred_te = knn_PCA.predict(X_te_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.295"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_te, knn_pred_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN with PCA after tuning produced a test accuracy of 30& compared with test accuracy of 28% for KNN without PCA after tuning. Once again the model with PCA performed slightly better.Thus, we will use PCA data for the next classifier KNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector with PCA and Kernel Trick and Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try SVM w/ PCA and kernel trick\n",
    "# grid search for params\n",
    "svc_grid = SVC(random_state=42)\n",
    "\n",
    "param_grid = { \n",
    "    'gamma': [0.00001, 0.0001, 0.01],\n",
    "    'C': [1, 10]\n",
    "}\n",
    "\n",
    "svc_grid = GridSearchCV(svc_grid, param_grid, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'gamma': 0.01}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_grid.fit(X_tr_new, y_tr)\n",
    "svc_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=42, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "svc = svc_grid.best_estimator_\n",
    "print(svc_grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=42, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.fit(X_tr_new, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_predict_te = svc.predict(X_te_new)\n",
    "accuracy_score(y_te, svc_predict_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support vector with PCA and hyer-paramater tuning only achieved 32% test accuracy. Slightly better than KNN but most worse than random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will train a logistic regression model using parameters {solver = 'lbfgs', and multi_clas = 'ovr'}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression(random_state=42, solver = 'lbfgs', multi_class='ovr').fit(X_tr_new, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_pred = log_reg.predict(X_te_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.175"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_te, log_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very low accuracy (17%) when using logistic regression after PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now try ensemble learning (stacking) using Support Vector SVC(32% accuracy), KNN(30% accuracy) and Random Forest(50% accuracy) to see if it can increase prediction accuracy on the testing set. We choose to not include logistic regression because it performed very poorly (17% test accuracy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('KNN', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=7, p=2,\n",
       "           weights='uniform')), ('svc', SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamm...ators=500, n_jobs=None,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False))],\n",
       "         flatten_transform=None, n_jobs=None, voting='hard', weights=None)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "voting_clf = VotingClassifier(estimators=[('KNN', knn_PCA),('svc',svc),('RF', new_rfc)], voting='hard')\n",
    "voting_clf.fit(X_tr_new, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_pred = voting_clf.predict(X_te_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38125"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_te, voting_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf = VotingClassifier(estimators=[('svc',svc),('RF', new_rfc)], voting='hard')\n",
    "voting_clf.fit(X_tr_new, y_tr)\n",
    "voting_pred = voting_clf.predict(X_te_new)\n",
    "accuracy_score(y_te, voting_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stacking only Support Vector(32% accuracy) and Random Forest (50% accuracy) gives us a slightly slightly better accuracy of 41%, but it's still worse than using random forest alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[64,  6,  3,  3,  1,  0,  1,  0,  2,  0],\n",
       "       [15, 46,  4,  2,  6,  0,  4,  1,  1,  1],\n",
       "       [27,  9, 24,  4,  4,  3,  5,  0,  4,  0],\n",
       "       [21,  6,  4, 43,  2,  1,  2,  1,  0,  0],\n",
       "       [16,  8,  6,  6, 31,  5,  0,  4,  4,  0],\n",
       "       [26,  2,  0, 12,  6, 24,  0,  6,  3,  1],\n",
       "       [29, 17,  5,  3,  4,  0, 20,  0,  2,  0],\n",
       "       [12,  8,  3,  3, 10, 10,  1, 26,  5,  2],\n",
       "       [15,  5,  1, 10,  3,  3,  7,  7, 27,  2],\n",
       "       [21,  5,  3,  5,  3,  9,  1,  2,  8, 23]], dtype=int64)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_te, voting_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the confusion matrix, we can see:\n",
    "A lot of different digits were wrongly classified as 1s\n",
    "A lot of 7 were misclassified as 2s, 5s and 6s (this happened in random forest as well)\n",
    "A lot of 6 were misclassified as 4s (this happened in random forest as well)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion for Models with 2000 Datapoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of the tested models: Random Forest, SVC , Logistics Regression, KNN, and a stacked ensemble of the models, it appears that Random Forest with PCA attained the highest test accuracy of ~50%, followed by SVC with ~32%, and the stacked ensemble of these two model achieved ~41%. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Model Trained with Entire Original Dataset of 73257 samples VS 2000 samples "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The part below is beyond the scope of the project, but I'm a bit curious how random forest would perform if trained with the entire dataset 73257 samples instead of 2000 samples. Due to the very long run-time on such large dataset, I will only try this with the best model, not the rest of the models that performed more poorly to see how much better random forest would perform using 73257 training data on the same test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set (73257, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "# load-in whole data set and pre-process the exact same way\n",
    "data = loadmat(tr_set)\n",
    "X_tr, y_tr = data['X'], data['y']\n",
    "X_tr, y_tr = X_tr.transpose((3,0,1,2)), y_tr[:,0]\n",
    "X_tr=np.array(X_tr)\n",
    "y_tr= np.array(y_tr)\n",
    "# convert RGB to grayscale for feature engineering\n",
    "def rgb2gray(img_data):\n",
    "    return np.expand_dims(np.dot(img_data, [0.3, 0.6, 0.1]), axis=3)\n",
    "\n",
    "X_tr_gr = rgb2gray(X_tr).astype(np.float32) # converts gray training set to float values\n",
    "X_tr = X_tr_gr # replace original training set\n",
    "print(\"Training Set\", X_tr.shape)\n",
    "X_tr_resized = X_tr.reshape(73257, 32*32*1)\n",
    "sc_X = StandardScaler()\n",
    "X_tr= sc_X.fit_transform(X_tr_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67625"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_newPCA = RandomForestClassifier(bootstrap=False, class_weight=None,\n",
    "            criterion='entropy', max_depth=50, max_features='auto',\n",
    "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "            min_impurity_split=None, min_samples_leaf=1,\n",
    "            min_samples_split=3, min_weight_fraction_leaf=0.0,\n",
    "            n_estimators=500, n_jobs=None, oob_score=False,\n",
    "            random_state=42, verbose=0, warm_start=False)\n",
    "rf_newPCA.fit(X_tr, y_tr)\n",
    "new_predictRf = rf_newPCA.predict(X_te_scaled)\n",
    "accuracy_score(y_te, new_predictRf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model using the entire original training dataset of 73257 data performed significantly better with test accuracy of 68%, compared with the same model trained using 2000 training data achieveing test accuracy of 50%. However, 68% is still not a satisfactory performance, thus Convolutional neural network model is utilized instead, see notebooks 2 and 3. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
